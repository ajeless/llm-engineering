{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c342de-624a-4c9e-8f0b-9b07f514c7d5",
   "metadata": {},
   "source": [
    "# **Perplexity Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11665172-792f-4462-9d45-08fae7b7c999",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![Perplexity](assets/perplexity/Boundless-Book/Black.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55eed0-7c15-4cb3-93fb-ea866d662eb0",
   "metadata": {},
   "source": [
    "## Python Requests SDK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a40b0386-307f-4799-a43a-ae9146921332",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Perplexity, a large language model (LLM) developed by Perplexity AI. I was created with the goal of providing accurate, well-synthesized, and context-aware natural language understanding and generation to assist users across many domains and tasks.\n",
      "\n",
      "My **strengths** include:\n",
      "\n",
      "- **Deep language understanding**: I excel at grasping nuances, context, idioms, and subtle meanings in text, enabling versatile application in conversational AI, information retrieval, and more[1].\n",
      "- **Versatility**: I can address a wide range of text-centric tasks such as answering questions, summarizing content, and generating suggestions[1][3].\n",
      "- **Scalability**: Given enough data and computation, I can perform well across diverse topics and complexity levels[1].\n",
      "\n",
      "My **weaknesses** are:\n",
      "\n",
      "- **Hallucination**: Occasionally, I may generate plausible-sounding but factually incorrect information, a common challenge for LLMs[1].\n",
      "- **Bias**: I can reflect and sometimes amplify biases present in my training data, requiring cautious interpretation of outputs[1][3].\n",
      "- **Resource demand**: Training and operation require significant computational resources, which can impact cost and environmental footprint[1][3].\n",
      "\n",
      "It is preferable to choose me over other models when you need a reliable, flexible, and context-savvy language assistant that can handle a broad spectrum of tasks without being limited to a single domain. My ability to synthesize information effectively and engage in coherent dialogue makes me well-suited for applications involving complex language understanding, nuanced responses, or multi-turn conversations[1][3]. However, if your priority is multimodal generation (e.g., images alongside text) or highly specialized reasoning in a niche area, other models like Google Gemini might be more appropriate[3].\n",
      "\n",
      "In summary, I provide a strong balance of language comprehension and generation capabilities with a focus on accuracy and usability, making me an excellent choice for general-purpose AI language tasks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from lib.ws_minify import ws_minify\n",
    "\n",
    "\n",
    "# Compose a user prompt. `textwrap.dedent` removes the common leading indentation,\n",
    "# which keeps the code readable without sending leading spaces to the model.\n",
    "user_prompt = ws_minify(\"\"\"\n",
    "    State your model and the company or lab that created you.\n",
    "    Then discuss a little bit about why you were created and what are your strengths and weaknesses.\n",
    "    Finally discuss situations in which it would be preferable to choose you over other models.\n",
    "\"\"\")\n",
    "\n",
    "url = \"https://api.perplexity.ai/chat/completions\"\n",
    "PERPLEXITY_API_KEY = os.environ[\"PERPLEXITY_API_KEY\"]\n",
    "current_model = \"sonar\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {PERPLEXITY_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": current_model,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "result = response.json()\n",
    "\n",
    "print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e34581-b7da-4a9e-93af-363c255ae83c",
   "metadata": {},
   "source": [
    "## OpenAI Python SDK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a2f9fd-c430-4559-b5a0-a50d4829a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am based on the GPT-4 architecture, developed by OpenAI. I was created to facilitate a wide range of natural language understanding and generation tasks, including answering questions, providing explanations, assisting with creative writing, and offering coding support among others[1].\n",
      "\n",
      "My **strengths** include high versatility across diverse tasks, generating human-like and contextually relevant text, and easy integration through a robust API. This makes interactions feel natural and effective for many applications[1]. However, my **weaknesses** involve potentially high operational costs due to computational demands, risks of generating misinformation if not monitored carefully, and a level of opacity about how conclusions are reached, commonly described as the \"black box\" problem[1].\n",
      "\n",
      "Choosing me over other models would be preferable in situations that demand a broad, flexible language model capable of creative and coherent text production, such as content generation, conversational agents, or complex problem-solving tasks. My versatility and quality of output often exceed those of some other specialized or more narrowly focused models. On the other hand, models like Google Gemini might be preferred for tasks requiring multimodal capabilities (text and images) or strong reasoning over large datasets, while cost-effective models might suit budget-constrained contexts better[1][3].\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from lib.ws_minify import ws_minify\n",
    "\n",
    "\n",
    "# Compose a user prompt. `textwrap.dedent` removes the common leading indentation,\n",
    "# which keeps the code readable without sending leading spaces to the model.\n",
    "user_prompt = ws_minify(\"\"\"\n",
    "    State your model and the company or lab that created you.\n",
    "    Then discuss a little bit about why you were created and what are your strengths and weaknesses.\n",
    "    Finally discuss situations in which it would be preferable to choose you over other models.\n",
    "\"\"\")\n",
    "\n",
    "url = \"https://api.perplexity.ai\"\n",
    "PERPLEXITY_API_KEY = os.environ[\"PERPLEXITY_API_KEY\"]\n",
    "current_model = \"sonar\"\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "# Configure OpenAI client to use Anthropic's API\n",
    "client = OpenAI(\n",
    "    api_key=PERPLEXITY_API_KEY,\n",
    "    base_url=url,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(model=current_model, messages=messages)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bb751-319c-4077-98b4-4c27aaa9090d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
