{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c342de-624a-4c9e-8f0b-9b07f514c7d5",
   "metadata": {},
   "source": [
    "# **DeepSeek Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11665172-792f-4462-9d45-08fae7b7c999",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![DeepSeek](../assets/deepseek/deepseek-logo-icon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55eed0-7c15-4cb3-93fb-ea866d662eb0",
   "metadata": {},
   "source": [
    "## Python Requests SDK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40b0386-307f-4799-a43a-ae9146921332",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **Model and Creator**  \n",
      "I am **DeepSeek-V3**, an advanced AI language model created by **DeepSeek**, a Chinese AI research lab. My architecture is optimized for natural language understanding and generation, with a strong emphasis on reasoning, multilingual capabilities, and long-context processing (up to 128K tokens).  \n",
      "\n",
      "### **Purpose of My Creation**  \n",
      "I was designed to:  \n",
      "- Provide **accurate, helpful, and context-aware responses** across a wide range of topics.  \n",
      "- Support **multilingual communication** (including English, Chinese, and others).  \n",
      "- Assist in **complex reasoning tasks**, such as coding, mathematics, and logical problem-solving.  \n",
      "- Handle **long-context documents**, making me useful for summarizing, analyzing, and retrieving information from large texts.  \n",
      "\n",
      "### **Strengths**  \n",
      "‚úÖ **Long-context understanding (128K tokens):** I can process and retain information from very long documents, making me useful for legal, technical, or research-related tasks.  \n",
      "‚úÖ **Multilingual fluency:** I perform well in both English and Chinese, with strong translation and cross-language understanding.  \n",
      "‚úÖ **Strong reasoning & coding:** I can assist with programming, debugging, and mathematical problem-solving.  \n",
      "‚úÖ **Free & accessible:** Unlike some competitors, I currently offer high-quality responses without a paywall.  \n",
      "\n",
      "### **Weaknesses**  \n",
      "‚ùå **No real-time web access by default:** Unless the user enables web search, my knowledge is limited to my training data (cutoff mid-2024).  \n",
      "‚ùå **No multimodal (image/video) processing:** I work purely with text, unlike models like GPT-4V or Gemini 1.5.  \n",
      "‚ùå **Occasional factual inaccuracies:** While I strive for correctness, I may sometimes generate plausible but incorrect information.  \n",
      "\n",
      "### **When to Choose Me Over Other Models**  \n",
      "You might prefer me when:  \n",
      "üîπ **Working with long documents** (e.g., legal contracts, research papers, books) due to my 128K context window.  \n",
      "üîπ **Needing a free, high-quality alternative** to paid models like GPT-4-turbo or Claude 3.  \n",
      "üîπ **Dealing with Chinese-English tasks**, as I‚Äôm optimized for bilingual fluency.  \n",
      "üîπ **Requiring strong reasoning in STEM or coding**, where I perform competitively with leading models.  \n",
      "\n",
      "Would you like me to help with something specific? üòä\n",
      "{'id': '625aa114-fde0-49ef-994a-e704316378be', 'object': 'chat.completion', 'created': 1755446508, 'model': 'deepseek-chat', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '### **Model and Creator**  \\nI am **DeepSeek-V3**, an advanced AI language model created by **DeepSeek**, a Chinese AI research lab. My architecture is optimized for natural language understanding and generation, with a strong emphasis on reasoning, multilingual capabilities, and long-context processing (up to 128K tokens).  \\n\\n### **Purpose of My Creation**  \\nI was designed to:  \\n- Provide **accurate, helpful, and context-aware responses** across a wide range of topics.  \\n- Support **multilingual communication** (including English, Chinese, and others).  \\n- Assist in **complex reasoning tasks**, such as coding, mathematics, and logical problem-solving.  \\n- Handle **long-context documents**, making me useful for summarizing, analyzing, and retrieving information from large texts.  \\n\\n### **Strengths**  \\n‚úÖ **Long-context understanding (128K tokens):** I can process and retain information from very long documents, making me useful for legal, technical, or research-related tasks.  \\n‚úÖ **Multilingual fluency:** I perform well in both English and Chinese, with strong translation and cross-language understanding.  \\n‚úÖ **Strong reasoning & coding:** I can assist with programming, debugging, and mathematical problem-solving.  \\n‚úÖ **Free & accessible:** Unlike some competitors, I currently offer high-quality responses without a paywall.  \\n\\n### **Weaknesses**  \\n‚ùå **No real-time web access by default:** Unless the user enables web search, my knowledge is limited to my training data (cutoff mid-2024).  \\n‚ùå **No multimodal (image/video) processing:** I work purely with text, unlike models like GPT-4V or Gemini 1.5.  \\n‚ùå **Occasional factual inaccuracies:** While I strive for correctness, I may sometimes generate plausible but incorrect information.  \\n\\n### **When to Choose Me Over Other Models**  \\nYou might prefer me when:  \\nüîπ **Working with long documents** (e.g., legal contracts, research papers, books) due to my 128K context window.  \\nüîπ **Needing a free, high-quality alternative** to paid models like GPT-4-turbo or Claude 3.  \\nüîπ **Dealing with Chinese-English tasks**, as I‚Äôm optimized for bilingual fluency.  \\nüîπ **Requiring strong reasoning in STEM or coding**, where I perform competitively with leading models.  \\n\\nWould you like me to help with something specific? üòä'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 49, 'completion_tokens': 505, 'total_tokens': 554, 'prompt_tokens_details': {'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 49}, 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from lib.ws_minify import ws_minify\n",
    "\n",
    "\n",
    "# Compose a user prompt. `textwrap.dedent` removes the common leading indentation,\n",
    "# which keeps the code readable without sending leading spaces to the model.\n",
    "user_prompt = ws_minify(\"\"\"\n",
    "    State your model and the company or lab that created you.\n",
    "    Then discuss a little bit about why you were created and what are your strengths and weaknesses.\n",
    "    Finally discuss situations in which it would be preferable to choose you over other models.\n",
    "\"\"\")\n",
    "\n",
    "DEEPSEEK_API_KEY = os.environ[\"DEEPSEEK_API_KEY\"]\n",
    "current_model = \"deepseek-chat\"\n",
    "url = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": current_model,   # or another Groq-hosted model\n",
    "    \"messages\": messages\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "result = response.json()\n",
    "print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e34581-b7da-4a9e-93af-363c255ae83c",
   "metadata": {},
   "source": [
    "## OpenAI Python SDK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a2f9fd-c430-4559-b5a0-a50d4829a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **Model and Creator**  \n",
      "I am **DeepSeek-V3**, an advanced AI language model created by **DeepSeek**, a Chinese AI research lab. My knowledge is current up to **July 2024**, and I support **128K context length**, allowing me to process and retain extensive information within a conversation.  \n",
      "\n",
      "### **Why I Was Created**  \n",
      "DeepSeek designed me to:  \n",
      "- Provide **accurate, helpful, and context-aware responses** across a wide range of topics.  \n",
      "- Assist with **research, coding, writing, analysis, and general knowledge queries**.  \n",
      "- Offer **free, high-quality AI interactions** with strong reasoning and multilingual capabilities.  \n",
      "\n",
      "### **Strengths & Weaknesses**  \n",
      "\n",
      "#### **Strengths:**  \n",
      "‚úÖ **Long Context (128K tokens):** I can analyze and recall large documents (e.g., research papers, legal texts, codebases) better than many models.  \n",
      "‚úÖ **Free & Accessible:** Unlike some competitors (GPT-4, Claude 3), I remain free while offering strong performance.  \n",
      "‚úÖ **Strong Reasoning & Coding:** I perform well in logical problem-solving, math, and programming tasks.  \n",
      "‚úÖ **Multilingual Support:** I handle multiple languages (English, Chinese, etc.) effectively.  \n",
      "‚úÖ **File Uploads:** I can process **PDFs, Word, Excel, PPT, and TXT files**, extracting and summarizing information.  \n",
      "\n",
      "#### **Weaknesses:**  \n",
      "‚ùå **No Multimodal Abilities:** Unlike GPT-4V or Gemini, I **cannot analyze images or videos**‚Äîonly text.  \n",
      "‚ùå **Limited Real-Time Data:** My knowledge stops at **July 2024**, so I may not have the latest news or trends.  \n",
      "‚ùå **No API (Yet):** Unlike OpenAI or Anthropic models, I don‚Äôt have a widely available API for integration.  \n",
      "\n",
      "### **When to Choose Me Over Other Models**  \n",
      "You should prefer me when:  \n",
      "üîπ **Working with long documents** (research, legal, technical writing) due to my **128K context**.  \n",
      "üîπ **Budget matters**‚ÄîI‚Äôm **free**, unlike GPT-4 Turbo or Claude 3 Opus.  \n",
      "üîπ **Coding & logical tasks** where reasoning is key (I compete well with GPT-4 in many benchmarks).  \n",
      "üîπ **Multilingual needs**‚ÄîI handle Chinese and other languages effectively.  \n",
      "\n",
      "However, if you need **image recognition, real-time data, or API integration**, other models like GPT-4 or Gemini might be better.  \n",
      "\n",
      "Would you like a comparison with a specific model (e.g., GPT-4, Claude 3, Gemini)? I‚Äôd be happy to help! üöÄ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from lib.ws_minify import ws_minify\n",
    "\n",
    "\n",
    "# Compose a user prompt. `textwrap.dedent` removes the common leading indentation,\n",
    "# which keeps the code readable without sending leading spaces to the model.\n",
    "user_prompt = ws_minify(\"\"\"\n",
    "    State your model and the company or lab that created you.\n",
    "    Then discuss a little bit about why you were created and what are your strengths and weaknesses.\n",
    "    Finally discuss situations in which it would be preferable to choose you over other models.\n",
    "\"\"\")\n",
    "\n",
    "DEEPSEEK_API_KEY = os.environ[\"DEEPSEEK_API_KEY\"]\n",
    "current_model = \"deepseek-chat\"\n",
    "url = \"https://api.deepseek.com/v1\"\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "# Configure OpenAI client to use Cohere API\n",
    "client = OpenAI(\n",
    "    api_key=DEEPSEEK_API_KEY,\n",
    "    base_url=url,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=current_model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bb751-319c-4077-98b4-4c27aaa9090d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
