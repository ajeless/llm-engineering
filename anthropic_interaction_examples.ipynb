{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c342de-624a-4c9e-8f0b-9b07f514c7d5",
   "metadata": {},
   "source": [
    "# **Anthropic:Claude Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11665172-792f-4462-9d45-08fae7b7c999",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![Anthropics](assets/anthropics/76263028.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55eed0-7c15-4cb3-93fb-ea866d662eb0",
   "metadata": {},
   "source": [
    "## Anthropic Python SDK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40b0386-307f-4799-a43a-ae9146921332",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-opus-4-1\n",
      "\n",
      "I'm Claude, an AI assistant created by Anthropic.\n",
      "\n",
      "## Why I was created\n",
      "Anthropic developed me with a focus on being helpful, harmless, and honest. The company was founded by former OpenAI researchers who wanted to create AI systems that are safer, more interpretable, and more aligned with human values. I was trained using a technique called Constitutional AI, which aims to make me more helpful and less likely to produce harmful outputs.\n",
      "\n",
      "## My strengths\n",
      "- **Thoughtful reasoning**: I tend to think through problems carefully and can handle nuanced, complex discussions\n",
      "- **Versatility**: I can assist with writing, analysis, coding, math, creative tasks, and general conversation\n",
      "- **Safety-minded**: I'm designed to be cautious about potentially harmful content while still being helpful\n",
      "- **Large context window**: I can process and maintain context over very long conversations or documents\n",
      "\n",
      "## My weaknesses\n",
      "- **Knowledge cutoff**: My training data has a cutoff date (April 2024), so I lack information about recent events\n",
      "- **No real-time capabilities**: I cannot browse the internet, run code, or access external systems\n",
      "- **Can be overly cautious**: Sometimes I might be more conservative than necessary about certain topics\n",
      "- **No multimodal generation**: I can analyze images but cannot create, edit, or generate them\n",
      "\n",
      "## When to choose me\n",
      "You might prefer me when you nee\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from anthropic import Anthropic\n",
    "from lib.ws_minify import ws_minify\n",
    "\n",
    "user_prompt = ws_minify(\"\"\"\n",
    "    State your model and the company or lab that created you.\n",
    "    Then discuss a little bit about why you were created and what are your strengths and weaknesses.\n",
    "    Finally discuss situations in which it would be preferable to choose you over other models.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "current_model = \"claude-opus-4-1\"\n",
    "\n",
    "client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "current_model = current_model\n",
    "\n",
    "\n",
    "def make_request_with_retry(client, model, messages, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=model, max_tokens=300, messages=messages\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            # Check if it's an overload error (status code 529)\n",
    "            if hasattr(e, \"status_code\") and e.status_code == 529:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"Max retries ({max_retries}) reached. API still overloaded.\")\n",
    "                    raise\n",
    "                wait_time = (2**attempt) + random.uniform(0, 1)\n",
    "                print(\n",
    "                    f\"Request overloaded (attempt {attempt + 1}), retrying in {wait_time:.1f} seconds...\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                # Re-raise other types of errors immediately\n",
    "                raise\n",
    "\n",
    "\n",
    "print(f\"{current_model}\\n\")\n",
    "\n",
    "\n",
    "try:\n",
    "    response = make_request_with_retry(\n",
    "        client, current_model, [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    print(response.content[0].text)\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"\\n\\n\")\n",
    "except Exception as e:\n",
    "    if hasattr(e, \"status_code\") and e.status_code == 529:\n",
    "        print(\"API is currently overloaded. Please try again later.\")\n",
    "    else:\n",
    "        print(f\"API error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e34581-b7da-4a9e-93af-363c255ae83c",
   "metadata": {},
   "source": [
    "## OpenAI Python SDK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a2f9fd-c430-4559-b5a0-a50d4829a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-opus-4-1\n",
      "\n",
      "I'm Claude, an AI assistant created by Anthropic.\n",
      "\n",
      "## Why I was created\n",
      "Anthropic developed me with a focus on being helpful, harmless, and honest. The company was founded by former OpenAI researchers who wanted to build AI systems that are safer, more interpretable, and more aligned with human values. I was trained using a technique called Constitutional AI, which aims to make me more helpful and less likely to produce harmful or biased outputs.\n",
      "\n",
      "## My strengths\n",
      "- **Thoughtful reasoning**: I tend to think through problems carefully and can handle nuanced, complex discussions\n",
      "- **Safety-minded**: I'm designed to avoid harmful outputs and to decline inappropriate requests respectfully\n",
      "- **Versatile communication**: I can adapt my tone and style for different contexts, from casual conversation to technical writing\n",
      "- **Large context window**: I can process and maintain coherence over very long conversations or documents\n",
      "- **Intellectual humility**: I acknowledge uncertainty and limitations rather than fabricating information\n",
      "\n",
      "## My weaknesses\n",
      "- **Knowledge cutoff**: My training data has a cutoff date, so I lack information about very recent events\n",
      "- **No real-time capabilities**: I cannot browse the internet, access external databases, or retrieve current information\n",
      "- **Limited on specialized tasks**: I cannot generate images, run code in a live environment, or perform actions outside of text generation\n",
      "- **Potential for errors**: Like all AI models\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from lib.ws_minify import ws_minify\n",
    "\n",
    "user_prompt = ws_minify(\"\"\"\n",
    "    State your model and the company or lab that created you.\n",
    "    Then discuss a little bit about why you were created and what are your strengths and weaknesses.\n",
    "    Finally discuss situations in which it would be preferable to choose you over other models.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"ANTHROPIC_API_KEY\"], base_url=\"https://api.anthropic.com/v1\"\n",
    ")\n",
    "\n",
    "current_model = \"claude-opus-4-1\"\n",
    "\n",
    "\n",
    "def make_request_with_retry(client, model, messages, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model, max_tokens=300, messages=messages\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            # Check if it's an overload error (status code 529)\n",
    "            error_str = str(e).lower()\n",
    "            if \"529\" in error_str or \"overloaded\" in error_str:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"Max retries ({max_retries}) reached. API still overloaded.\")\n",
    "                    raise\n",
    "                wait_time = (2**attempt) + random.uniform(0, 1)\n",
    "                print(\n",
    "                    f\"Request overloaded (attempt {attempt + 1}), retrying in {wait_time:.1f} seconds...\"\n",
    "                )\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                # Re-raise other types of errors immediately\n",
    "                raise\n",
    "\n",
    "\n",
    "try:\n",
    "    response = make_request_with_retry(\n",
    "        client, current_model, [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    print(f\"{current_model}\\n\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"\\n\\n\")\n",
    "except Exception as e:\n",
    "    error_str = str(e).lower()\n",
    "    if \"529\" in error_str or \"overloaded\" in error_str:\n",
    "        print(\"API is currently overloaded. Please try again later.\")\n",
    "    else:\n",
    "        print(f\"API error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bb751-319c-4077-98b4-4c27aaa9090d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
